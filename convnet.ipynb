{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86d31ea8",
   "metadata": {},
   "source": [
    "# Neural Net classification of music genre\n",
    "\n",
    "## I. Loading and processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fe01132a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th colspan=\"10\" halign=\"left\">chroma_cens</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"3\" halign=\"left\">tonnetz</th>\n",
       "      <th colspan=\"7\" halign=\"left\">zcr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statistics</th>\n",
       "      <th colspan=\"10\" halign=\"left\">kurtosis</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"3\" halign=\"left\">std</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>min</th>\n",
       "      <th>skew</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>07</th>\n",
       "      <th>08</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.180653</td>\n",
       "      <td>5.230309</td>\n",
       "      <td>0.249321</td>\n",
       "      <td>1.347620</td>\n",
       "      <td>1.482478</td>\n",
       "      <td>0.531371</td>\n",
       "      <td>1.481593</td>\n",
       "      <td>2.691455</td>\n",
       "      <td>0.866868</td>\n",
       "      <td>1.341231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054125</td>\n",
       "      <td>0.012226</td>\n",
       "      <td>0.012111</td>\n",
       "      <td>5.758890</td>\n",
       "      <td>0.459473</td>\n",
       "      <td>0.085629</td>\n",
       "      <td>0.071289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.089872</td>\n",
       "      <td>0.061448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.888963</td>\n",
       "      <td>0.760539</td>\n",
       "      <td>0.345297</td>\n",
       "      <td>2.295201</td>\n",
       "      <td>1.654031</td>\n",
       "      <td>0.067592</td>\n",
       "      <td>1.366848</td>\n",
       "      <td>1.054094</td>\n",
       "      <td>0.108103</td>\n",
       "      <td>0.619185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063831</td>\n",
       "      <td>0.014212</td>\n",
       "      <td>0.017740</td>\n",
       "      <td>2.824694</td>\n",
       "      <td>0.466309</td>\n",
       "      <td>0.084578</td>\n",
       "      <td>0.063965</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.716724</td>\n",
       "      <td>0.069330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.527563</td>\n",
       "      <td>-0.077654</td>\n",
       "      <td>-0.279610</td>\n",
       "      <td>0.685883</td>\n",
       "      <td>1.937570</td>\n",
       "      <td>0.880839</td>\n",
       "      <td>-0.923192</td>\n",
       "      <td>-0.927232</td>\n",
       "      <td>0.666617</td>\n",
       "      <td>1.038546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040730</td>\n",
       "      <td>0.012691</td>\n",
       "      <td>0.014759</td>\n",
       "      <td>6.808415</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.053114</td>\n",
       "      <td>0.041504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.193303</td>\n",
       "      <td>0.044861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.702245</td>\n",
       "      <td>-0.291193</td>\n",
       "      <td>2.196742</td>\n",
       "      <td>-0.234449</td>\n",
       "      <td>1.367364</td>\n",
       "      <td>0.998411</td>\n",
       "      <td>1.770694</td>\n",
       "      <td>1.604566</td>\n",
       "      <td>0.521217</td>\n",
       "      <td>1.982386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074358</td>\n",
       "      <td>0.017952</td>\n",
       "      <td>0.013921</td>\n",
       "      <td>21.434212</td>\n",
       "      <td>0.452148</td>\n",
       "      <td>0.077515</td>\n",
       "      <td>0.071777</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.542325</td>\n",
       "      <td>0.040800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.193837</td>\n",
       "      <td>-0.198527</td>\n",
       "      <td>0.201546</td>\n",
       "      <td>0.258556</td>\n",
       "      <td>0.775204</td>\n",
       "      <td>0.084794</td>\n",
       "      <td>-0.289294</td>\n",
       "      <td>-0.816410</td>\n",
       "      <td>0.043851</td>\n",
       "      <td>-0.804761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095003</td>\n",
       "      <td>0.022492</td>\n",
       "      <td>0.021355</td>\n",
       "      <td>16.669037</td>\n",
       "      <td>0.469727</td>\n",
       "      <td>0.047225</td>\n",
       "      <td>0.040039</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>3.189831</td>\n",
       "      <td>0.030993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155316</th>\n",
       "      <td>-0.490129</td>\n",
       "      <td>0.463834</td>\n",
       "      <td>2.321970</td>\n",
       "      <td>-0.084352</td>\n",
       "      <td>1.662914</td>\n",
       "      <td>2.115189</td>\n",
       "      <td>-0.237794</td>\n",
       "      <td>5.695442</td>\n",
       "      <td>0.830353</td>\n",
       "      <td>1.951819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128410</td>\n",
       "      <td>0.022547</td>\n",
       "      <td>0.019816</td>\n",
       "      <td>4.448255</td>\n",
       "      <td>0.172852</td>\n",
       "      <td>0.028773</td>\n",
       "      <td>0.028320</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.955388</td>\n",
       "      <td>0.012385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155317</th>\n",
       "      <td>-0.461559</td>\n",
       "      <td>-0.229601</td>\n",
       "      <td>-0.496632</td>\n",
       "      <td>-0.422033</td>\n",
       "      <td>0.130612</td>\n",
       "      <td>-0.263825</td>\n",
       "      <td>-0.628103</td>\n",
       "      <td>-0.082687</td>\n",
       "      <td>-0.229483</td>\n",
       "      <td>-0.492753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132964</td>\n",
       "      <td>0.023548</td>\n",
       "      <td>0.026527</td>\n",
       "      <td>3.270612</td>\n",
       "      <td>0.196289</td>\n",
       "      <td>0.031116</td>\n",
       "      <td>0.027832</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>1.283060</td>\n",
       "      <td>0.019059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155318</th>\n",
       "      <td>0.552473</td>\n",
       "      <td>-0.110498</td>\n",
       "      <td>-0.532014</td>\n",
       "      <td>0.263131</td>\n",
       "      <td>-0.224011</td>\n",
       "      <td>-0.530972</td>\n",
       "      <td>1.713526</td>\n",
       "      <td>1.418444</td>\n",
       "      <td>1.325197</td>\n",
       "      <td>0.120333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108324</td>\n",
       "      <td>0.017540</td>\n",
       "      <td>0.020471</td>\n",
       "      <td>2.356727</td>\n",
       "      <td>0.212891</td>\n",
       "      <td>0.038450</td>\n",
       "      <td>0.037109</td>\n",
       "      <td>0.003418</td>\n",
       "      <td>0.828569</td>\n",
       "      <td>0.017904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155319</th>\n",
       "      <td>-0.176901</td>\n",
       "      <td>0.187208</td>\n",
       "      <td>-0.050664</td>\n",
       "      <td>0.368843</td>\n",
       "      <td>0.066005</td>\n",
       "      <td>-0.857354</td>\n",
       "      <td>-0.780860</td>\n",
       "      <td>0.626281</td>\n",
       "      <td>-0.630938</td>\n",
       "      <td>-0.787229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088311</td>\n",
       "      <td>0.018328</td>\n",
       "      <td>0.017936</td>\n",
       "      <td>6.188604</td>\n",
       "      <td>0.167480</td>\n",
       "      <td>0.041480</td>\n",
       "      <td>0.038086</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>1.818740</td>\n",
       "      <td>0.020133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155320</th>\n",
       "      <td>0.489665</td>\n",
       "      <td>1.862421</td>\n",
       "      <td>0.854461</td>\n",
       "      <td>-0.103666</td>\n",
       "      <td>-0.249835</td>\n",
       "      <td>0.360283</td>\n",
       "      <td>-0.366701</td>\n",
       "      <td>0.033578</td>\n",
       "      <td>-0.834606</td>\n",
       "      <td>-1.154845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091421</td>\n",
       "      <td>0.020312</td>\n",
       "      <td>0.016794</td>\n",
       "      <td>21.756050</td>\n",
       "      <td>0.845215</td>\n",
       "      <td>0.075141</td>\n",
       "      <td>0.044434</td>\n",
       "      <td>0.004395</td>\n",
       "      <td>4.687204</td>\n",
       "      <td>0.137205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106574 rows × 518 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "feature    chroma_cens                                                    \\\n",
       "statistics    kurtosis                                                     \n",
       "number              01        02        03        04        05        06   \n",
       "track_id                                                                   \n",
       "2             7.180653  5.230309  0.249321  1.347620  1.482478  0.531371   \n",
       "3             1.888963  0.760539  0.345297  2.295201  1.654031  0.067592   \n",
       "5             0.527563 -0.077654 -0.279610  0.685883  1.937570  0.880839   \n",
       "10            3.702245 -0.291193  2.196742 -0.234449  1.367364  0.998411   \n",
       "20           -0.193837 -0.198527  0.201546  0.258556  0.775204  0.084794   \n",
       "...                ...       ...       ...       ...       ...       ...   \n",
       "155316       -0.490129  0.463834  2.321970 -0.084352  1.662914  2.115189   \n",
       "155317       -0.461559 -0.229601 -0.496632 -0.422033  0.130612 -0.263825   \n",
       "155318        0.552473 -0.110498 -0.532014  0.263131 -0.224011 -0.530972   \n",
       "155319       -0.176901  0.187208 -0.050664  0.368843  0.066005 -0.857354   \n",
       "155320        0.489665  1.862421  0.854461 -0.103666 -0.249835  0.360283   \n",
       "\n",
       "feature                                             ...   tonnetz            \\\n",
       "statistics                                          ...       std             \n",
       "number            07        08        09        10  ...        04        05   \n",
       "track_id                                            ...                       \n",
       "2           1.481593  2.691455  0.866868  1.341231  ...  0.054125  0.012226   \n",
       "3           1.366848  1.054094  0.108103  0.619185  ...  0.063831  0.014212   \n",
       "5          -0.923192 -0.927232  0.666617  1.038546  ...  0.040730  0.012691   \n",
       "10          1.770694  1.604566  0.521217  1.982386  ...  0.074358  0.017952   \n",
       "20         -0.289294 -0.816410  0.043851 -0.804761  ...  0.095003  0.022492   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "155316     -0.237794  5.695442  0.830353  1.951819  ...  0.128410  0.022547   \n",
       "155317     -0.628103 -0.082687 -0.229483 -0.492753  ...  0.132964  0.023548   \n",
       "155318      1.713526  1.418444  1.325197  0.120333  ...  0.108324  0.017540   \n",
       "155319     -0.780860  0.626281 -0.630938 -0.787229  ...  0.088311  0.018328   \n",
       "155320     -0.366701  0.033578 -0.834606 -1.154845  ...  0.091421  0.020312   \n",
       "\n",
       "feature                     zcr                                          \\\n",
       "statistics             kurtosis       max      mean    median       min   \n",
       "number            06         01        01        01        01        01   \n",
       "track_id                                                                  \n",
       "2           0.012111   5.758890  0.459473  0.085629  0.071289  0.000000   \n",
       "3           0.017740   2.824694  0.466309  0.084578  0.063965  0.000000   \n",
       "5           0.014759   6.808415  0.375000  0.053114  0.041504  0.000000   \n",
       "10          0.013921  21.434212  0.452148  0.077515  0.071777  0.000000   \n",
       "20          0.021355  16.669037  0.469727  0.047225  0.040039  0.000977   \n",
       "...              ...        ...       ...       ...       ...       ...   \n",
       "155316      0.019816   4.448255  0.172852  0.028773  0.028320  0.003906   \n",
       "155317      0.026527   3.270612  0.196289  0.031116  0.027832  0.002441   \n",
       "155318      0.020471   2.356727  0.212891  0.038450  0.037109  0.003418   \n",
       "155319      0.017936   6.188604  0.167480  0.041480  0.038086  0.004883   \n",
       "155320      0.016794  21.756050  0.845215  0.075141  0.044434  0.004395   \n",
       "\n",
       "feature                         \n",
       "statistics      skew       std  \n",
       "number            01        01  \n",
       "track_id                        \n",
       "2           2.089872  0.061448  \n",
       "3           1.716724  0.069330  \n",
       "5           2.193303  0.044861  \n",
       "10          3.542325  0.040800  \n",
       "20          3.189831  0.030993  \n",
       "...              ...       ...  \n",
       "155316      0.955388  0.012385  \n",
       "155317      1.283060  0.019059  \n",
       "155318      0.828569  0.017904  \n",
       "155319      1.818740  0.020133  \n",
       "155320      4.687204  0.137205  \n",
       "\n",
       "[106574 rows x 518 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils.load_data import fma_load\n",
    "\n",
    "features = fma_load('data/fma_metadata/features.csv')\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "047e694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = fma_load('data/fma_metadata/tracks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9e7891ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bit_rate', 'comments', 'composer', 'date_created', 'date_recorded',\n",
       "       'duration', 'favorites', 'genre_top', 'genres', 'genres_all',\n",
       "       'information', 'interest', 'language_code', 'license', 'listens',\n",
       "       'lyricist', 'number', 'publisher', 'tags', 'title'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks['track'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "160bc7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tracks['track','genre_top']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8a10d9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de labels: (track, genre_top)\n",
      "Rock                   14182\n",
      "Experimental           10608\n",
      "Electronic              9372\n",
      "Hip-Hop                 3552\n",
      "Folk                    2803\n",
      "Pop                     2332\n",
      "Instrumental            2079\n",
      "International           1389\n",
      "Classical               1230\n",
      "Jazz                     571\n",
      "Old-Time / Historic      554\n",
      "Spoken                   423\n",
      "Country                  194\n",
      "Soul-RnB                 175\n",
      "Blues                    110\n",
      "Easy Listening            24\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f'Nombre de labels: {y.value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90a80331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de labels non définis: 56976\n"
     ]
    }
   ],
   "source": [
    "print(f'Nombre de labels non définis: {y.isna().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08df92b",
   "metadata": {},
   "source": [
    "## II. Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f19faeb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th colspan=\"10\" halign=\"left\">chroma_cens</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"3\" halign=\"left\">tonnetz</th>\n",
       "      <th colspan=\"7\" halign=\"left\">zcr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statistics</th>\n",
       "      <th colspan=\"10\" halign=\"left\">kurtosis</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"3\" halign=\"left\">std</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>min</th>\n",
       "      <th>skew</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>07</th>\n",
       "      <th>08</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.180653</td>\n",
       "      <td>5.230309</td>\n",
       "      <td>0.249321</td>\n",
       "      <td>1.347620</td>\n",
       "      <td>1.482478</td>\n",
       "      <td>0.531371</td>\n",
       "      <td>1.481593</td>\n",
       "      <td>2.691455</td>\n",
       "      <td>0.866868</td>\n",
       "      <td>1.341231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054125</td>\n",
       "      <td>0.012226</td>\n",
       "      <td>0.012111</td>\n",
       "      <td>5.758890</td>\n",
       "      <td>0.459473</td>\n",
       "      <td>0.085629</td>\n",
       "      <td>0.071289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.089872</td>\n",
       "      <td>0.061448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.888963</td>\n",
       "      <td>0.760539</td>\n",
       "      <td>0.345297</td>\n",
       "      <td>2.295201</td>\n",
       "      <td>1.654031</td>\n",
       "      <td>0.067592</td>\n",
       "      <td>1.366848</td>\n",
       "      <td>1.054094</td>\n",
       "      <td>0.108103</td>\n",
       "      <td>0.619185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063831</td>\n",
       "      <td>0.014212</td>\n",
       "      <td>0.017740</td>\n",
       "      <td>2.824694</td>\n",
       "      <td>0.466309</td>\n",
       "      <td>0.084578</td>\n",
       "      <td>0.063965</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.716724</td>\n",
       "      <td>0.069330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.527563</td>\n",
       "      <td>-0.077654</td>\n",
       "      <td>-0.279610</td>\n",
       "      <td>0.685883</td>\n",
       "      <td>1.937570</td>\n",
       "      <td>0.880839</td>\n",
       "      <td>-0.923192</td>\n",
       "      <td>-0.927232</td>\n",
       "      <td>0.666617</td>\n",
       "      <td>1.038546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040730</td>\n",
       "      <td>0.012691</td>\n",
       "      <td>0.014759</td>\n",
       "      <td>6.808415</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.053114</td>\n",
       "      <td>0.041504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.193303</td>\n",
       "      <td>0.044861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.702245</td>\n",
       "      <td>-0.291193</td>\n",
       "      <td>2.196742</td>\n",
       "      <td>-0.234449</td>\n",
       "      <td>1.367364</td>\n",
       "      <td>0.998411</td>\n",
       "      <td>1.770694</td>\n",
       "      <td>1.604566</td>\n",
       "      <td>0.521217</td>\n",
       "      <td>1.982386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074358</td>\n",
       "      <td>0.017952</td>\n",
       "      <td>0.013921</td>\n",
       "      <td>21.434212</td>\n",
       "      <td>0.452148</td>\n",
       "      <td>0.077515</td>\n",
       "      <td>0.071777</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.542325</td>\n",
       "      <td>0.040800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.193837</td>\n",
       "      <td>-0.198527</td>\n",
       "      <td>0.201546</td>\n",
       "      <td>0.258556</td>\n",
       "      <td>0.775204</td>\n",
       "      <td>0.084794</td>\n",
       "      <td>-0.289294</td>\n",
       "      <td>-0.816410</td>\n",
       "      <td>0.043851</td>\n",
       "      <td>-0.804761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095003</td>\n",
       "      <td>0.022492</td>\n",
       "      <td>0.021355</td>\n",
       "      <td>16.669037</td>\n",
       "      <td>0.469727</td>\n",
       "      <td>0.047225</td>\n",
       "      <td>0.040039</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>3.189831</td>\n",
       "      <td>0.030993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155316</th>\n",
       "      <td>-0.490129</td>\n",
       "      <td>0.463834</td>\n",
       "      <td>2.321970</td>\n",
       "      <td>-0.084352</td>\n",
       "      <td>1.662914</td>\n",
       "      <td>2.115189</td>\n",
       "      <td>-0.237794</td>\n",
       "      <td>5.695442</td>\n",
       "      <td>0.830353</td>\n",
       "      <td>1.951819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128410</td>\n",
       "      <td>0.022547</td>\n",
       "      <td>0.019816</td>\n",
       "      <td>4.448255</td>\n",
       "      <td>0.172852</td>\n",
       "      <td>0.028773</td>\n",
       "      <td>0.028320</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.955388</td>\n",
       "      <td>0.012385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155317</th>\n",
       "      <td>-0.461559</td>\n",
       "      <td>-0.229601</td>\n",
       "      <td>-0.496632</td>\n",
       "      <td>-0.422033</td>\n",
       "      <td>0.130612</td>\n",
       "      <td>-0.263825</td>\n",
       "      <td>-0.628103</td>\n",
       "      <td>-0.082687</td>\n",
       "      <td>-0.229483</td>\n",
       "      <td>-0.492753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132964</td>\n",
       "      <td>0.023548</td>\n",
       "      <td>0.026527</td>\n",
       "      <td>3.270612</td>\n",
       "      <td>0.196289</td>\n",
       "      <td>0.031116</td>\n",
       "      <td>0.027832</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>1.283060</td>\n",
       "      <td>0.019059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155318</th>\n",
       "      <td>0.552473</td>\n",
       "      <td>-0.110498</td>\n",
       "      <td>-0.532014</td>\n",
       "      <td>0.263131</td>\n",
       "      <td>-0.224011</td>\n",
       "      <td>-0.530972</td>\n",
       "      <td>1.713526</td>\n",
       "      <td>1.418444</td>\n",
       "      <td>1.325197</td>\n",
       "      <td>0.120333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108324</td>\n",
       "      <td>0.017540</td>\n",
       "      <td>0.020471</td>\n",
       "      <td>2.356727</td>\n",
       "      <td>0.212891</td>\n",
       "      <td>0.038450</td>\n",
       "      <td>0.037109</td>\n",
       "      <td>0.003418</td>\n",
       "      <td>0.828569</td>\n",
       "      <td>0.017904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155319</th>\n",
       "      <td>-0.176901</td>\n",
       "      <td>0.187208</td>\n",
       "      <td>-0.050664</td>\n",
       "      <td>0.368843</td>\n",
       "      <td>0.066005</td>\n",
       "      <td>-0.857354</td>\n",
       "      <td>-0.780860</td>\n",
       "      <td>0.626281</td>\n",
       "      <td>-0.630938</td>\n",
       "      <td>-0.787229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088311</td>\n",
       "      <td>0.018328</td>\n",
       "      <td>0.017936</td>\n",
       "      <td>6.188604</td>\n",
       "      <td>0.167480</td>\n",
       "      <td>0.041480</td>\n",
       "      <td>0.038086</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>1.818740</td>\n",
       "      <td>0.020133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155320</th>\n",
       "      <td>0.489665</td>\n",
       "      <td>1.862421</td>\n",
       "      <td>0.854461</td>\n",
       "      <td>-0.103666</td>\n",
       "      <td>-0.249835</td>\n",
       "      <td>0.360283</td>\n",
       "      <td>-0.366701</td>\n",
       "      <td>0.033578</td>\n",
       "      <td>-0.834606</td>\n",
       "      <td>-1.154845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091421</td>\n",
       "      <td>0.020312</td>\n",
       "      <td>0.016794</td>\n",
       "      <td>21.756050</td>\n",
       "      <td>0.845215</td>\n",
       "      <td>0.075141</td>\n",
       "      <td>0.044434</td>\n",
       "      <td>0.004395</td>\n",
       "      <td>4.687204</td>\n",
       "      <td>0.137205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106574 rows × 518 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "feature    chroma_cens                                                    \\\n",
       "statistics    kurtosis                                                     \n",
       "number              01        02        03        04        05        06   \n",
       "track_id                                                                   \n",
       "2             7.180653  5.230309  0.249321  1.347620  1.482478  0.531371   \n",
       "3             1.888963  0.760539  0.345297  2.295201  1.654031  0.067592   \n",
       "5             0.527563 -0.077654 -0.279610  0.685883  1.937570  0.880839   \n",
       "10            3.702245 -0.291193  2.196742 -0.234449  1.367364  0.998411   \n",
       "20           -0.193837 -0.198527  0.201546  0.258556  0.775204  0.084794   \n",
       "...                ...       ...       ...       ...       ...       ...   \n",
       "155316       -0.490129  0.463834  2.321970 -0.084352  1.662914  2.115189   \n",
       "155317       -0.461559 -0.229601 -0.496632 -0.422033  0.130612 -0.263825   \n",
       "155318        0.552473 -0.110498 -0.532014  0.263131 -0.224011 -0.530972   \n",
       "155319       -0.176901  0.187208 -0.050664  0.368843  0.066005 -0.857354   \n",
       "155320        0.489665  1.862421  0.854461 -0.103666 -0.249835  0.360283   \n",
       "\n",
       "feature                                             ...   tonnetz            \\\n",
       "statistics                                          ...       std             \n",
       "number            07        08        09        10  ...        04        05   \n",
       "track_id                                            ...                       \n",
       "2           1.481593  2.691455  0.866868  1.341231  ...  0.054125  0.012226   \n",
       "3           1.366848  1.054094  0.108103  0.619185  ...  0.063831  0.014212   \n",
       "5          -0.923192 -0.927232  0.666617  1.038546  ...  0.040730  0.012691   \n",
       "10          1.770694  1.604566  0.521217  1.982386  ...  0.074358  0.017952   \n",
       "20         -0.289294 -0.816410  0.043851 -0.804761  ...  0.095003  0.022492   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "155316     -0.237794  5.695442  0.830353  1.951819  ...  0.128410  0.022547   \n",
       "155317     -0.628103 -0.082687 -0.229483 -0.492753  ...  0.132964  0.023548   \n",
       "155318      1.713526  1.418444  1.325197  0.120333  ...  0.108324  0.017540   \n",
       "155319     -0.780860  0.626281 -0.630938 -0.787229  ...  0.088311  0.018328   \n",
       "155320     -0.366701  0.033578 -0.834606 -1.154845  ...  0.091421  0.020312   \n",
       "\n",
       "feature                     zcr                                          \\\n",
       "statistics             kurtosis       max      mean    median       min   \n",
       "number            06         01        01        01        01        01   \n",
       "track_id                                                                  \n",
       "2           0.012111   5.758890  0.459473  0.085629  0.071289  0.000000   \n",
       "3           0.017740   2.824694  0.466309  0.084578  0.063965  0.000000   \n",
       "5           0.014759   6.808415  0.375000  0.053114  0.041504  0.000000   \n",
       "10          0.013921  21.434212  0.452148  0.077515  0.071777  0.000000   \n",
       "20          0.021355  16.669037  0.469727  0.047225  0.040039  0.000977   \n",
       "...              ...        ...       ...       ...       ...       ...   \n",
       "155316      0.019816   4.448255  0.172852  0.028773  0.028320  0.003906   \n",
       "155317      0.026527   3.270612  0.196289  0.031116  0.027832  0.002441   \n",
       "155318      0.020471   2.356727  0.212891  0.038450  0.037109  0.003418   \n",
       "155319      0.017936   6.188604  0.167480  0.041480  0.038086  0.004883   \n",
       "155320      0.016794  21.756050  0.845215  0.075141  0.044434  0.004395   \n",
       "\n",
       "feature                         \n",
       "statistics      skew       std  \n",
       "number            01        01  \n",
       "track_id                        \n",
       "2           2.089872  0.061448  \n",
       "3           1.716724  0.069330  \n",
       "5           2.193303  0.044861  \n",
       "10          3.542325  0.040800  \n",
       "20          3.189831  0.030993  \n",
       "...              ...       ...  \n",
       "155316      0.955388  0.012385  \n",
       "155317      1.283060  0.019059  \n",
       "155318      0.828569  0.017904  \n",
       "155319      1.818740  0.020133  \n",
       "155320      4.687204  0.137205  \n",
       "\n",
       "[106574 rows x 518 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "27c3fc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_df = features['mfcc']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d071ed7",
   "metadata": {},
   "source": [
    "## III. Classification with simple feed-forward MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e87b8369",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4820/4117377123.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mfcc_df['genre_top'] = y\n",
      "/tmp/ipykernel_4820/4117377123.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mfcc_df.dropna(inplace=True)\n",
      "/tmp/ipykernel_4820/4117377123.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mfcc_df.drop(columns=['genre_top'],inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "mfcc_df['genre_top'] = y\n",
    "mfcc_df.dropna(inplace=True)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(mfcc_df['genre_top'])\n",
    "\n",
    "mfcc_df.drop(columns=['genre_top'],inplace=True)\n",
    "\n",
    "# mfcc_df shape: (num_tracks, num_columns)\n",
    "scaler = StandardScaler()\n",
    "scaled = scaler.fit_transform(mfcc_df.values)\n",
    "\n",
    "num_tracks = len(mfcc_df)\n",
    "num_columns = mfcc_df.shape[1]\n",
    "\n",
    "# Choose number of statistics manually (or detect)\n",
    "num_statistics = 7\n",
    "num_numbers = num_columns // num_statistics  # compute dynamically\n",
    "\n",
    "tensor = mfcc_df.values.reshape(num_tracks, num_statistics, num_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8e11e899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([49598, 1, 7, 20]) torch.Size([49598])\n",
      "Classes: ['Blues' 'Classical' 'Country' 'Easy Listening' 'Electronic'\n",
      " 'Experimental' 'Folk' 'Hip-Hop' 'Instrumental' 'International' 'Jazz'\n",
      " 'Old-Time / Historic' 'Pop' 'Rock' 'Soul-RnB' 'Spoken']\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor(tensor,dtype=torch.float32)\n",
    "X = X.unsqueeze(1)\n",
    "\n",
    "y = torch.tensor(y_encoded, dtype=torch.long)\n",
    "\n",
    "print(X.shape,y.shape)\n",
    "print(\"Classes:\", le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6df38798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "all_train = TensorDataset(X_train,y_train)\n",
    "\n",
    "num_train = int(0.8 * len(all_train))\n",
    "\n",
    "trainset, valset = torch.utils.data.random_split(all_train, [num_train, len(all_train) - num_train])\n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "valloader = DataLoader(valset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f061ef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8c296d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=16):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # flattened size after conv+pool\n",
    "        self.fc = nn.Linear(64*3*10, 128)\n",
    "        self.out = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "90fcf607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training consists of gradient steps over mini batch of data\n",
    "def train(model, trainloader, criterion, optimizer, epoch, num_epochs):\n",
    "    # We enter train mode. This is useless for the linear model\n",
    "    # but is important for layers such as dropout, batchnorm, ...\n",
    "    model.train()\n",
    "\n",
    "    loop = tqdm(trainloader)\n",
    "    loop.set_description(f'Training Epoch [{epoch + 1}/{num_epochs}]')\n",
    "\n",
    "    # We iterate over the mini batches of our data\n",
    "    for inputs, targets in loop:\n",
    "\n",
    "        # Erase any previously stored gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        outputs = model(inputs) # Forwards stage (prediction with current weights)\n",
    "        loss = criterion(outputs, targets) # loss evaluation\n",
    "\n",
    "        loss.backward() # Back propagation (evaluate gradients)\n",
    "\n",
    "\n",
    "        # Making gradient step on the batch (this function takes care of the gradient step for us)\n",
    "        optimizer.step()\n",
    "\n",
    "def validation(model, valloader, loss):\n",
    "    # Do not compute gradient, since we do not need it for validation step\n",
    "    with torch.no_grad():\n",
    "        # We enter evaluation mode.\n",
    "        model.eval()\n",
    "\n",
    "        total = 0 # keep track of currently used samples\n",
    "        running_loss = 0.0 # accumulated loss without averagind\n",
    "        accuracy = 0.0 # accumulated accuracy without averagind (number of correct predictions)\n",
    "\n",
    "        loop = tqdm(valloader) # This is for the progress bar\n",
    "        loop.set_description('Validation in progress')\n",
    "\n",
    "\n",
    "        # We again iterate over the batches of validation data. batch_size does not play any role here\n",
    "        for inputs, targets in loop:\n",
    "            # Run samples through our net\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Total number of used samples\n",
    "            total += inputs.shape[0]\n",
    "\n",
    "            # Multiply loss by the batch size to erase averagind on the batch\n",
    "            running_loss += inputs.shape[0] * loss(outputs, targets).item()\n",
    "\n",
    "            # how many correct predictions\n",
    "            accuracy += (outputs.argmax(dim=1) == targets).sum().item()\n",
    "\n",
    "            # set nice progress meassage\n",
    "            loop.set_postfix(val_loss=(running_loss / total), val_acc=(accuracy / total))       \n",
    "        \n",
    "        return running_loss / total, accuracy / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "951ca78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Net + training parameters\n",
    "num_epochs = 100 # how many passes over the whole train data\n",
    "lr = 0.003 # learning rate\n",
    "momentum = 0.9 # momentum\n",
    "\n",
    "net = ConvNet() # Our neural net\n",
    "criterion = nn.CrossEntropyLoss() # Loss function to be optimized\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr) # Optimization algorithm\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f5b135b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [1/100]: 100%|██████████| 992/992 [00:12<00:00, 81.99it/s] \n",
      "Validation in progress: 100%|██████████| 248/248 [00:01<00:00, 191.14it/s, val_acc=0.533, val_loss=1.45]\n",
      "Training Epoch [2/100]: 100%|██████████| 992/992 [00:10<00:00, 91.51it/s]\n",
      "Validation in progress: 100%|██████████| 248/248 [00:01<00:00, 178.34it/s, val_acc=0.559, val_loss=1.39]\n",
      "Training Epoch [3/100]: 100%|██████████| 992/992 [00:10<00:00, 92.88it/s]\n",
      "Validation in progress: 100%|██████████| 248/248 [00:01<00:00, 176.12it/s, val_acc=0.561, val_loss=1.37]\n",
      "Training Epoch [4/100]: 100%|██████████| 992/992 [00:10<00:00, 92.30it/s]\n",
      "Validation in progress: 100%|██████████| 248/248 [00:01<00:00, 187.31it/s, val_acc=0.569, val_loss=1.34]\n",
      "Training Epoch [5/100]: 100%|██████████| 992/992 [00:10<00:00, 92.97it/s]\n",
      "Validation in progress: 100%|██████████| 248/248 [00:01<00:00, 186.22it/s, val_acc=0.583, val_loss=1.31]\n",
      "Training Epoch [6/100]: 100%|██████████| 992/992 [00:10<00:00, 91.82it/s]\n",
      "Validation in progress: 100%|██████████| 248/248 [00:01<00:00, 167.44it/s, val_acc=0.583, val_loss=1.31]\n",
      "Training Epoch [7/100]: 100%|██████████| 992/992 [00:10<00:00, 91.69it/s]\n",
      "Validation in progress: 100%|██████████| 248/248 [00:01<00:00, 175.57it/s, val_acc=0.583, val_loss=1.31]\n",
      "Training Epoch [8/100]: 100%|██████████| 992/992 [00:10<00:00, 91.95it/s]\n",
      "Validation in progress: 100%|██████████| 248/248 [00:01<00:00, 172.18it/s, val_acc=0.581, val_loss=1.31]\n",
      "Training Epoch [9/100]: 100%|██████████| 992/992 [00:10<00:00, 92.22it/s]\n",
      "Validation in progress: 100%|██████████| 248/248 [00:01<00:00, 171.82it/s, val_acc=0.591, val_loss=1.28]\n",
      "Training Epoch [10/100]: 100%|██████████| 992/992 [00:10<00:00, 93.37it/s]\n",
      "Validation in progress: 100%|██████████| 248/248 [00:01<00:00, 170.76it/s, val_acc=0.593, val_loss=1.29]\n",
      "Training Epoch [11/100]: 100%|██████████| 992/992 [00:10<00:00, 93.11it/s]\n",
      "Validation in progress: 100%|██████████| 248/248 [00:01<00:00, 169.00it/s, val_acc=0.6, val_loss=1.27]  \n",
      "Training Epoch [12/100]: 100%|██████████| 992/992 [00:10<00:00, 93.45it/s]\n",
      "Validation in progress: 100%|██████████| 248/248 [00:01<00:00, 172.86it/s, val_acc=0.599, val_loss=1.28]\n",
      "Training Epoch [13/100]: 100%|██████████| 992/992 [00:10<00:00, 92.98it/s] \n",
      "Validation in progress: 100%|██████████| 248/248 [00:01<00:00, 171.27it/s, val_acc=0.591, val_loss=1.3] \n",
      "Training Epoch [14/100]: 100%|██████████| 992/992 [00:10<00:00, 94.17it/s] \n",
      "Validation in progress: 100%|██████████| 248/248 [00:01<00:00, 183.54it/s, val_acc=0.602, val_loss=1.27]\n",
      "Training Epoch [15/100]: 100%|██████████| 992/992 [00:10<00:00, 93.08it/s]\n",
      "Validation in progress: 100%|██████████| 248/248 [00:01<00:00, 174.46it/s, val_acc=0.611, val_loss=1.24]\n",
      "Training Epoch [16/100]: 100%|██████████| 992/992 [00:10<00:00, 93.92it/s]\n",
      "Validation in progress: 100%|██████████| 248/248 [00:01<00:00, 166.10it/s, val_acc=0.609, val_loss=1.25]\n",
      "Training Epoch [17/100]: 100%|██████████| 992/992 [00:10<00:00, 93.44it/s]\n",
      "Validation in progress: 100%|██████████| 248/248 [00:01<00:00, 165.92it/s, val_acc=0.611, val_loss=1.24]\n",
      "Training Epoch [18/100]: 100%|██████████| 992/992 [00:10<00:00, 93.01it/s]\n",
      "Validation in progress: 100%|██████████| 248/248 [00:01<00:00, 166.81it/s, val_acc=0.611, val_loss=1.26]\n",
      "Training Epoch [19/100]: 100%|██████████| 992/992 [00:10<00:00, 94.34it/s]\n",
      "Validation in progress: 100%|██████████| 248/248 [00:01<00:00, 176.38it/s, val_acc=0.614, val_loss=1.24]\n",
      "Training Epoch [20/100]: 100%|██████████| 992/992 [00:10<00:00, 92.48it/s]\n",
      "Validation in progress: 100%|██████████| 248/248 [00:01<00:00, 172.79it/s, val_acc=0.613, val_loss=1.24]\n",
      "Training Epoch [21/100]: 100%|██████████| 992/992 [00:10<00:00, 93.74it/s]\n",
      "Validation in progress: 100%|██████████| 248/248 [00:01<00:00, 162.37it/s, val_acc=0.618, val_loss=1.24]\n",
      "Training Epoch [22/100]: 100%|██████████| 992/992 [00:10<00:00, 93.00it/s]\n",
      "Validation in progress: 100%|██████████| 248/248 [00:01<00:00, 177.71it/s, val_acc=0.613, val_loss=1.24]\n",
      "Training Epoch [23/100]: 100%|██████████| 992/992 [00:10<00:00, 93.11it/s]\n",
      "Validation in progress: 100%|██████████| 248/248 [00:01<00:00, 166.42it/s, val_acc=0.618, val_loss=1.24]\n",
      "Training Epoch [24/100]: 100%|██████████| 992/992 [00:10<00:00, 94.41it/s] \n",
      "Validation in progress: 100%|██████████| 248/248 [00:01<00:00, 164.94it/s, val_acc=0.618, val_loss=1.25]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping triggered at epoch 24\n",
      "✔ Best model restored\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# num_epochs indicates the number of passes over the data\n",
    "\n",
    "patience = 5\n",
    "best_loss = float('inf')\n",
    "wait = 0\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # makes one pass over the train data and updates weights\n",
    "    train(net, trainloader, criterion, optimizer, epoch, num_epochs)\n",
    "\n",
    "    # makes one pass over validation data and provides validation statistics\n",
    "    val_loss, val_acc = validation(net, valloader, criterion)\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # check si amélioration\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        wait = 0\n",
    "        best_model_state = net.state_dict()   # on sauvegarde le meilleur modèle\n",
    "    else:\n",
    "        wait += 1\n",
    "\n",
    "    # early stopping déclenché ?\n",
    "    if wait >= patience:\n",
    "        print(f\"\\nEarly stopping triggered at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "# restaurer meilleur modèle\n",
    "net.load_state_dict(best_model_state)\n",
    "print(\"✔ Best model restored\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5d645486",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation in progress: 100%|██████████| 310/310 [00:02<00:00, 132.40it/s, val_acc=0.618, val_loss=1.22]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.6180443548387097 | Test loss: 1.222052727976153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "testset = TensorDataset(X_test,y_test)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_loss, test_acc = validation(net, testloader, criterion)\n",
    "print(f'Test accuracy: {test_acc} | Test loss: {test_loss}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
